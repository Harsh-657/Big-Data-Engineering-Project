# ğŸ“ DA-IICT Faculty Data Engine

> **A fully automated, AI-powered data pipeline that scrapes, transforms, stores, and intelligently serves DA-IICT faculty information through an interactive web interface.**

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.68+-green.svg)](https://fastapi.tiangolo.com/)
[![SQLite](https://img.shields.io/badge/Database-SQLite-lightgrey.svg)](https://www.sqlite.org/)
[![AI](https://img.shields.io/badge/AI-Sentence--BERT-orange.svg)](https://www.sbert.net/)
[![License](https://img.shields.io/badge/License-Educational-yellow.svg)]()

## ğŸŒŸ Live Demo

**ğŸš€ Try it yourself:** [faculty-finder.streamlit.app](https://faculty-finder.streamlit.app) *(Replace with your actual deployment URL)*

**Features:**
- ğŸ” **Smart Search:** Find faculty by name, department, or research interests
- ğŸ§  **AI-Powered:** Semantic search understands context, not just keywords
- âš¡ **Lightning Fast:** Pre-computed embeddings for instant results
- ğŸ“± **Mobile-Friendly:** Responsive design works on all devices

---

## âœ¨ Key Features

### ğŸ¯ Intelligent Search
- **Natural Language Queries:** Search "professors working on AI" instead of exact keywords
- **Context-Aware Results:** Finds "machine learning expert" when you search "neural networks"
- **Ranked by Relevance:** AI-powered similarity scoring puts best matches first

### ğŸ“Š Comprehensive Data
- **150+ Faculty Profiles:** Complete database of DA-IICT faculty
- **5 Categories:** Faculty, Adjunct, International, Distinguished, Visiting
- **Rich Information:** Name, email, phone, department, research areas, photos

### ğŸ› ï¸ Developer-Friendly
- **Modular Architecture:** Separate scripts for each pipeline phase
- **REST API Option:** JSON endpoints for integration with other apps
- **Well-Documented Code:** Clear comments and function docstrings
- **Easy Deployment:** One-click hosting on Streamlit Cloud

---

## ğŸ¯ Problem Statement

Manually collecting and maintaining information for hundreds of faculty members across multiple departments is:
- â° **Time-consuming** (days of manual copy-pasting)
- âŒ **Error-prone** (typos, outdated information)
- ğŸ”„ **Not scalable** (hard to update when changes occur)

**Our Solution:** An automated end-to-end data pipeline that eliminates manual work and ensures data consistency.

---

## ğŸ—ï¸ Pipeline Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DA-IICT FACULTY DATA PIPELINE (5 PHASES)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    ğŸ“¡ INGESTION        ğŸ”§ TRANSFORM         ğŸ’¾ STORAGE         ğŸ§  AI BRAIN        ğŸš€ SERVING
    â•â•â•â•â•â•â•â•â•â•â•â•        â•â•â•â•â•â•â•â•â•â•â•         â•â•â•â•â•â•â•â•â•â•â•        â•â•â•â•â•â•â•â•â•â•â•        â•â•â•â•â•â•â•â•â•â•
         
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                                            
    â”‚ DA-IICT  â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Website  â”‚â”€â”€â”€â”€â”€â”€>â”‚  Scraper â”‚â”€â”€â”€â”€â”€â”€â”€>â”‚  Clean   â”‚â”€â”€â”€â”€â”€>â”‚  SQLite   â”‚â”€â”€â”€â”€>â”‚Embeddingsâ”‚
    â”‚(5 Pages) â”‚       â”‚  (Py)    â”‚        â”‚Transform â”‚      â”‚ Database  â”‚     â”‚Generator â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â”‚                   â”‚                    â”‚                â”‚                 â”‚
         â”‚                   â”‚                    â”‚                â”‚                 â”‚
    Faculty Lists    BeautifulSoup      Email fixing        faculty.db        Vector AI
    Adjunct          HTTP Requests      Phone standards     ACID DB          Sentence-T
    International    HTML Parsing       Null handling                             â”‚
    Distinguished    Filtering          Deduplication                             â”‚
    Visiting                                                                       â–¼
         â”‚                   â”‚                    â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                   â–¼                    â–¼                          â”‚ .pkl     â”‚
    scrape_faculty.py    store_data.py      faculty.db                      â”‚Embeddingsâ”‚
         â”‚                                                                   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â–¼                                                                        â”‚
    daiict_faculty_final.csv                                                     â”‚
                                                                                  â–¼
                                                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                                          â”‚  Streamlit   â”‚
                                                                          â”‚   Web App    â”‚
                                                                          â”‚  (app.py)    â”‚
                                                                          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                                 â”‚
                                                                                 â–¼
                                                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                                      â”‚  ğŸŒ Web Interface   â”‚
                                                                      â”‚  â€¢ Semantic Search  â”‚
                                                                      â”‚  â€¢ Faculty Profiles â”‚
                                                                      â”‚  â€¢ Filters          â”‚
                                                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                      
                                                         ALTERNATIVE: FastAPI (main.py)
                                                                      â†“
                                                              REST API Endpoints
                                                              /faculty, /search, /stats
```

---

## ğŸ”„ The 5-Phase Pipeline

### **Phase 1: ğŸ“¥ Data Ingestion**
**Objective:** Extract raw faculty data from DA-IICT website

- **Target Sources:** 5 faculty category pages (Faculty, Adjunct, International, Distinguished, Visiting)
- **Technology:** Python with BeautifulSoup and Requests
- **Implementation:** `scrape_faculty.py`
- **Challenges Solved:**
  - Dynamic HTML structure navigation
  - Filtering non-faculty elements (navigation, footers, ads)
  - Handling missing or inconsistent page structures
  
**Output:** `daiict_faculty_final.csv` - Raw faculty profile data (names, emails, phone numbers, departments, photos)

---

### **Phase 2: ğŸ§¹ Data Transformation**
**Objective:** Clean and standardize extracted data

**Implementation:** `store_data.py`

**Initial Data Quality Assessment:**

Our scraping process identified several data quality issues that needed to be addressed before storage:

| Column Name | Missing Values | Data Type |
|-------------|----------------|-----------|
| Name | 0 | object |
| Education | 2 | object |
| Contact Number | 27 | object |
| Mail-Id | 1 | object |
| Area of Research | 3 | object |

*Table: Missing value analysis from scraped faculty data*

**Data Quality Issues Fixed:**
- âœ‰ï¸ Email formats: `user[at]daiict[dot]ac[dot]in` â†’ `user@daiict.ac.in`
- ğŸ“ Phone standardization: Various formats â†’ Consistent format (27 missing values handled)
- ğŸ“ Education field: 2 missing entries populated with "N/A"
- ğŸ”¬ Area of Research: 3 missing entries handled appropriately
- ğŸ–¼ï¸ Missing photos: Handle null/placeholder images
- ğŸ”¤ Text normalization: Trim whitespace, fix encoding issues

**Validation Rules:**
- Email format verification (1 invalid email corrected)
- Duplicate detection and removal
- Required field checks (name, department)
- Missing value imputation strategies

**Output:** Clean, validated, structured data ready for storage

---

### **Phase 3: ğŸ’¾ Data Storage**
**Objective:** Persist data in a reliable, queryable format

**Implementation:** `store_data.py` (same module as Phase 2)

**Database:** SQLite (`faculty.db`)

**Schema Design:**
```sql
CREATE TABLE faculty (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL,
    email TEXT UNIQUE NOT NULL,
    phone TEXT,
    department TEXT,
    category TEXT,
    photo_url TEXT,
    last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**Features:**
- âœ… UNIQUE constraint on email (prevents duplicates)
- ğŸ“… Automatic timestamp tracking
- ğŸ” Indexed fields for fast queries
- ğŸ’ª ACID compliance for data integrity

---

### **Phase 4: ğŸ§  AI Enhancement (Semantic Search)**
**Objective:** Enable intelligent, context-aware faculty search

**Implementation:** `generate_embeddings.py`

**Technology:** 
- **Sentence Transformers** (all-MiniLM-L6-v2 model)
- **Vector Embeddings** for semantic similarity
- **scikit-learn** for cosine similarity calculations

**How It Works:**
1. Converts faculty data (names, research areas, departments) into vector embeddings
2. Stores embeddings in `faculty_embeddings.pkl`
3. Enables natural language queries like "machine learning professor" to find relevant faculty
4. Returns results ranked by semantic similarity (not just keyword matching)

**Benefits:**
- ğŸ¯ **Smart Search:** Understands intent, not just keywords
- ğŸ” **Contextual Results:** Finds "AI researcher" when you search "neural networks"
- âš¡ **Fast Retrieval:** Pre-computed embeddings for instant results

**Output:** `faculty_embeddings.pkl` - Vector representations of faculty data

---

### **Phase 5: ğŸš€ User Interface & Serving**
**Objective:** Provide accessible interfaces for end users

#### **Option A: Streamlit Web App (Primary)**
**Implementation:** `app.py`

**Features:**
- ğŸ¨ Clean, modern interface
- ğŸ” Semantic search integration
- ğŸ“Š Real-time results display
- ğŸ“± Mobile-responsive design
- ğŸŒ One-click deployment to Streamlit Cloud

**Endpoints (via UI):**
- Search faculty by name/department/research area
- View detailed faculty profiles
- Filter by category (Faculty, Adjunct, etc.)

#### **Option B: FastAPI REST API (Alternative)**
**Implementation:** `main.py`

**Technology:** FastAPI (Python's fastest web framework)

**API Endpoints:**
```
GET  /faculty          â†’ Retrieve all faculty members
GET  /faculty/{id}     â†’ Get specific faculty by ID
GET  /search?q=name    â†’ Search faculty by name/department
GET  /stats            â†’ Get database statistics
```

**Response Format:** JSON (easily consumable by web/mobile apps)

**Benefits:**
- âš¡ Async support for high concurrency
- ğŸ“š Auto-generated API documentation (Swagger UI)
- ğŸ”’ Built-in validation and error handling

---

## ğŸ“‚ Project Structure

```
da-iict-faculty-engine/
â”‚
â”œâ”€â”€ ğŸ” scrape_faculty.py                    # Phase 1: Web scraping module
â”‚   â””â”€â”€ Extracts faculty data from DA-IICT website
â”‚
â”œâ”€â”€ ğŸ’¾ store_data.py                        # Phase 2 & 3: Data cleaning & storage
â”‚   â”œâ”€â”€ Cleans and transforms scraped data
â”‚   â””â”€â”€ Creates SQLite database
â”‚
â”œâ”€â”€ ğŸ§  generate_embeddings.py               # AI Enhancement: Semantic search
â”‚   â””â”€â”€ Creates vector embeddings for intelligent search
â”‚
â”œâ”€â”€ ğŸ¨ app.py                               # Phase 4: Streamlit web interface
â”‚   â”œâ”€â”€ Interactive faculty search UI
â”‚   â”œâ”€â”€ Semantic search integration
â”‚   â””â”€â”€ Real-time query results
â”‚
â”œâ”€â”€ ğŸ main.py                              # Alternative: FastAPI REST API
â”‚   â”œâ”€â”€ RESTful endpoints
â”‚   â””â”€â”€ JSON response formatting
â”‚
â”œâ”€â”€ ğŸ“Š daiict_faculty_final.csv             # Intermediate: Scraped raw data
â”‚
â”œâ”€â”€ ğŸ—„ï¸ faculty.db                           # Database: Cleaned faculty records
â”‚
â”œâ”€â”€ ğŸ§® faculty_embeddings.pkl               # AI Model: Vector embeddings
â”‚
â”œâ”€â”€ ğŸ“‹ requirements.txt                     # Python dependencies
â”‚   â”œâ”€â”€ streamlit
â”‚   â”œâ”€â”€ sentence-transformers
â”‚   â”œâ”€â”€ pandas
â”‚   â”œâ”€â”€ scikit-learn
â”‚   â””â”€â”€ torch (CPU version)
â”‚
â”œâ”€â”€ ğŸ“Š Assets/                              # Documentation assets
â”‚   â”œâ”€â”€ pipeline-architecture.svg          # Visual pipeline diagram
â”‚   â””â”€â”€ data-quality-analysis.jpg          # Missing values report
â”‚
â””â”€â”€ ğŸ“„ README.md                            # This file
```

---

## ğŸ“Š Project Documentation Assets

This repository includes visual documentation to help understand the data pipeline:

1. **Pipeline Architecture Diagram** (`pipeline-architecture.svg`)
   - Complete visual representation of all 4 phases
   - Shows data flow from web scraping to API serving
   - Includes technology stack and component details

2. **Data Quality Analysis** (`data-quality-analysis.jpg`)
   - Missing value analysis from initial scraping
   - Helps understand the cleaning challenges we faced
   - Referenced in Phase 2 documentation above

---

## ğŸš€ Quick Start Guide

### Prerequisites
- Python 3.8 or higher
- pip (Python package manager)
- Git (for version control)

### Installation & Setup

**1. Clone the repository**
```bash
git clone https://github.com/Harsh-657/Faculty-Finder.git
cd Faculty-Finder
```

**2. Install dependencies**
```bash
pip install -r requirements.txt
```

### Running the Pipeline (Execute in Order)

**Step 1: ğŸ“¡ Data Ingestion (Scraping)**
```bash
python scrape_faculty.py
```
- **Output:** `daiict_faculty_final.csv`
- **Purpose:** Extracts faculty data from 5 DA-IICT web pages
- **Duration:** ~30-60 seconds

**Step 2: ğŸ§¹ Data Transformation & Storage**
```bash
python store_data.py
```
- **Output:** `faculty.db` (SQLite database)
- **Purpose:** Cleans data and stores in structured format
- **Duration:** ~5-10 seconds

**Step 3: ğŸ§  AI Enhancement (Semantic Search)**
```bash
python generate_embeddings.py
```
- **Output:** `faculty_embeddings.pkl`
- **Purpose:** Creates vector embeddings for intelligent search
- **Duration:** ~30 seconds (first run, downloads AI model)

**Step 4: ğŸ¨ Launch the Web Interface**
```bash
streamlit run app.py
```
- **Access:** Opens automatically at `http://localhost:8501`
- **Features:** 
  - Interactive search interface
  - Semantic search powered by AI
  - Real-time faculty information display

### Alternative: REST API Server

If you prefer a REST API instead of the web interface:

```bash
python main.py
```
- Interactive API docs: `http://localhost:8000/docs`
- Alternative docs: `http://localhost:8000/redoc`
- Endpoints: `/faculty`, `/search`, `/stats`

---

## ğŸŒ Deployment (Public Hosting)

### Deploy to Streamlit Community Cloud (Free)

**Step 1: Prepare Repository**
```bash
git add .
git commit -m "Ready for deployment"
git push origin main
```

**Important:** Ensure these files are in your repository:
- `app.py`
- `requirements.txt`
- `daiict_faculty_final.csv`
- `faculty_embeddings.pkl`

**Note:** If `faculty_embeddings.pkl` exceeds 100MB, use Git LFS:
```bash
git lfs install
git lfs track "*.pkl"
git add .gitattributes
```

**Step 2: Deploy**

1. Go to [share.streamlit.io](https://share.streamlit.io)
2. Sign in with GitHub
3. Click **"New App"**
4. Select your repository (`Harsh-657/Faculty-Finder`)
5. Set main file: `app.py`
6. Click **"Deploy"**

**Step 3: Share**

Your app will be live at: `https://faculty-finder.streamlit.app`

Streamlit automatically:
- âœ… Installs dependencies from `requirements.txt`
- âœ… Loads your data files
- âœ… Provides free HTTPS hosting
- âœ… Auto-updates on git push

### Deploy to Other Platforms

<details>
<summary><b>Heroku Deployment</b></summary>

```bash
# Create Procfile
echo "web: streamlit run app.py --server.port=$PORT" > Procfile

# Deploy
heroku create faculty-finder-app
git push heroku main
```
</details>

<details>
<summary><b>AWS/GCP/Azure Deployment</b></summary>

Use Docker for containerized deployment:
```dockerfile
FROM python:3.9-slim
WORKDIR /app
COPY . .
RUN pip install -r requirements.txt
EXPOSE 8501
CMD ["streamlit", "run", "app.py"]
```
</details>

---

## ğŸ¯ Use Cases

This data engine can power:

1. **ğŸŒ Interactive Web Applications**
   - **Faculty Finder (Streamlit)** - Primary use case
   - Student portals with semantic search
   - Department dashboards
   - Academic advisor lookup tools

2. **ğŸ“± Mobile Apps**
   - Campus navigation apps
   - Faculty contact apps (via API)
   - Event management systems

3. **ğŸ“Š Data Analytics & Research**
   - Department size analysis
   - Research area clustering
   - Contact information audits
   - Faculty distribution reports
   - Publication co-authorship networks

4. **ğŸ¤– AI-Powered Applications**
   - **Semantic Search** - "Find professors working on climate change"
   - Chatbots & virtual assistants
   - Recommendation engines
   - Smart course-faculty matching

---

## ğŸ”§ Technical Highlights

### AI/ML Capabilities
- ğŸ§  **Semantic Search:** Sentence-BERT embeddings for context-aware search
- ğŸ¯ **Smart Ranking:** Cosine similarity for relevance scoring
- ğŸ“Š **Vector Storage:** Efficient pickle serialization for fast loading
- ğŸ”„ **Model Caching:** One-time download, persistent usage

### Performance Optimizations
- âš¡ Async database queries in FastAPI
- ğŸ—‚ï¸ Database indexing on frequently queried fields
- ğŸ’¾ Pre-computed embeddings for instant search
- ğŸš€ Streamlit caching for faster page loads

### Error Handling
- âŒ Graceful degradation when website structure changes
- ğŸ”„ Retry logic for network failures
- ğŸ“ Comprehensive logging for debugging
- âš ï¸ User-friendly error messages in UI

### Data Quality
- âœ… Email validation using regex
- ğŸ” Duplicate detection algorithms
- ğŸ“Š Data completeness reports
- ğŸ§¹ Automated data cleaning pipelines

---

## ğŸ“Š Sample API Response

```json
{
  "faculty": [
    {
      "id": 1,
      "name": "Dr. John Doe",
      "email": "john.doe@daiict.ac.in",
      "phone": "+91-79-12345678",
      "department": "Computer Science",
      "category": "Faculty",
      "photo_url": "https://example.com/photo.jpg",
      "last_updated": "2025-01-27T10:30:00Z"
    }
  ],
  "total": 150,
  "timestamp": "2025-01-27T12:00:00Z"
}
```

---

## ğŸ› ï¸ Future Enhancements

### Automation & Monitoring
- [ ] **Automated Scheduling:** Run scraper daily via cron jobs or GitHub Actions
- [ ] **Change Detection:** Email alerts when faculty info changes
- [ ] **Health Monitoring:** Track scraper success rates and API uptime
- [ ] **Version Control:** Historical tracking of faculty data changes

### Enhanced Search & Discovery
- [x] âœ… **Semantic Search** (Already implemented!)
- [ ] **Advanced Filters:** Multi-select department, research area, designation
- [ ] **Fuzzy Search:** Handle typos and partial names
- [ ] **Related Faculty:** "People also viewed" recommendations
- [ ] **Research Collaboration Graph:** Visualize co-authorship networks

### Data Enrichment
- [ ] **Publication Integration:** Fetch papers from Google Scholar
- [ ] **Citation Metrics:** H-index, total citations display
- [ ] **Course Mappings:** Link faculty to courses they teach
- [ ] **Office Hours:** Scrape and display availability

### User Experience
- [ ] **Dark Mode:** Toggle for Streamlit interface
- [ ] **Export Options:** Download search results as CSV/PDF
- [ ] **Bookmarking:** Save favorite faculty profiles
- [ ] **Share Links:** Direct URLs to specific faculty profiles

### Security & Scalability
- [ ] **Authentication:** User login for personalized features
- [ ] **Rate Limiting:** Prevent API abuse
- [ ] **CDN Integration:** Faster image loading
- [ ] **Database Migration:** Move to PostgreSQL for production scale
- [ ] **Cloud Deployment:** Host on AWS/GCP/Azure with auto-scaling

---

## ğŸ› Troubleshooting

### Common Issues

**Q: `ModuleNotFoundError: No module named 'sentence_transformers'`**
```bash
# Solution: Install dependencies
pip install -r requirements.txt
```

**Q: `generate_embeddings.py` is slow on first run**
- **Expected behavior:** The AI model (~80MB) downloads on first run
- Takes 30-60 seconds depending on internet speed
- Subsequent runs are instant (model is cached)

**Q: Streamlit app shows "File not found: faculty_embeddings.pkl"**
```bash
# Solution: Run embeddings generation first
python generate_embeddings.py
# Then run the app
streamlit run app.py
```

**Q: Web scraping fails with connection errors**
- **Possible causes:** DA-IICT website is down or structure changed
- Check internet connection
- Verify website is accessible: https://www.daiict.ac.in
- If structure changed, update selectors in `scrape_faculty.py`

**Q: `faculty.db` file is locked**
- Close any database browser tools (DB Browser for SQLite)
- Make sure no other scripts are accessing the database
- Restart your terminal/IDE

**Q: Streamlit app doesn't show on `localhost:8501`**
```bash
# Check if port is in use
netstat -ano | findstr :8501  # Windows
lsof -i :8501                 # Mac/Linux

# Use a different port
streamlit run app.py --server.port 8502
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is for educational purposes. Ensure compliance with DA-IICT's website terms of service before scraping.

---

## ğŸ‘¤ Author

**Harsh Jethwani (Harsh-657)**  
ğŸ”— GitHub: [@Harsh-657](https://github.com/Harsh-657)  
ğŸ“¦ Repository: [Faculty-Finder](https://github.com/Harsh-657/Faculty-Finder)

---

## ğŸ™ Acknowledgments

- DA-IICT for providing publicly accessible faculty information
- FastAPI team for the excellent web framework
- Python community for amazing libraries
